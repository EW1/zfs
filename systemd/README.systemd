systemd support for operating systems using ZFS
-----------------------------------------------

The NFS sharing unit
--------------------

`zfs-share-nfs.service` makes sure that ZFS automatically shares file systems
via NFS when they have been configured to be shared, and the NFS server is
enabled.  It also makes sure that the ZFS shares are re-exported whenever the
NFS server is reloaded or restarted.

For ZFS sharing to work, of course, the NFS server `nfs-utils` package and
associated services must be installed and enabled.

The RPM automatically takes care of enabling ZFS sharing when the `zfs-systemd`
package is installed.  Those of you installing from source will need to
enable it by hand for bootup with `systemctl enable zfs-share-nfs.service` and
of course `systemctl start zfs-share-nfs.service` to run it, after you have
reloaded the systemd daemon with `systemctl daemon-reload`.

The generator
-------------

This is a very basic ZFS unit generator, with support for boot-time generation
of ZFS units mounting all datasets in all available zpools imported at early
boot time, as well as importing all zpools known to zpool.cache at early boot
time, as soon as their backing devices have appeared.  It is intended as a
partial (and, eventually, a full) replacement for the initscript in Linux
systems with systemd as the init system.

WHAT IT DOES

Our systemd-zfs-generator lets systemd automount any filesystem that:
    - has a mountpoint,
    - is set to canmount=yes,
    - is not /sysroot or /
    - is not set to legacy

It also lets systemd import all zpools that have not yet been imported, with
the consequent implicit `zfs mount` of the datasets in these pools.  These
pools are only imported after their component devices have been (cold/hot)
plugged into the systemd device hierarchy.  This way, race conditions are
avoided.  Be ware that pools with cache devices may still be subject to race
conditions on boot.

HOW IT WORKS

- systemd starts up
- systemd runs /lib/systemd/system-generators/*
- these commands output unit files to the volatile directory /run/systemd/generator
- systemd loads the files created by our generator as units, just as it would have loaded from /etc/systemd/system
- in the process of starting local-fs.target, it pulls in the units for ZFS file systems created by our generator
- finally, the standard ZFS initscript is masked with a dummy unit so as to not cause any conflicts or mount any unintended file systems by error

The processes involved in systemd integration with ZFS are visually documented in the file `flowcharts.dia`.

AUTOMATIC MOUNT DEPENDENCY TRACKING

This generator will cooperate with interspersed file system types registered in /etc/fstab like this:

    /dev/sda3   /       ext3
    tank/home   /home   zfs  # this works if the file system was set to legacy and registered in /etc/fstab
    /dev/sda4   /home/user      ext4

This generator will operate correctly as well, even if any ZFS file systems were not set to legacy, but rather use the usual mountpoint property; a file system arrangement like this works fine too:

    /dev/sda3 is ext3 and is registered on fstab to mount on /
    tank/home is ZFS and its mountpoint property is set to /home
    /dev/sda4 is XFS and is registered on fstab to mount on /home/user

SUPPORT FOR ZFS ON ROOT

This generator will also operate correctly cooperate with systems where the root file system is on ZFS.

One caveat: the root file system must be registered as the first line in /etc/fstab:

    tank/RPOOL/fedora-16-root    /     zfs    defaults    0 0

Of course, GRUB2 does not yet have "official" support for ZFS on root, but with the Dracut support here, plus a little bit of trickery in the grub2-mkconfig script or hand-rolling grub.cfg, it can be done just fine.  Look at the patch in the grub2/ subdirectory.

AUTOMATIC MULTIBOOT SUPPORT

This generator also has a very particular feature that is very useful for multi-booting Linux systems.  Suppose you have an arrangement of ZFS file systems in your pool as follows:

    tank/RPOOL/fedora-16
    (mounts on / when Fedora 16 boots)
    tank/RPOOL/fedora-16/usr
    (mounts on /usr when Fedora 16 boots)
    tank/RPOOL/opensuse
    (mounts on / when OpenSUSE boots)
    tank/RPOOL/opensuse/var
    (mounts on /var when OpenSUSE boots)

Using the regular zfs mount -a command, this would obviously not work, because OpenSUSE's /var would be mounted atop Fedora's /var whenever you booted with Fedora, and vice versa.  So far, the traditional solution has been to set the operating system file systems like /var or /usr/local to legacy, and then to register them in the appopriate /etc/fstab files for each operating system.

To prevent this situation, this generator incorporates a very clever exclusion algorithm.  It will make systemd mount all file systems that are mountable, *except for those* that belong to operating systems other than the one being booted.

In other words: if you have a pool that contains a file system named ROOT or RPOOL, and this file system contains several subfilesystems, where each immediate child corresponds to an OS root file system you have installed, it will automatically skip mounting all file systems that do *not* belong to the operating system (that is to say, it will not mount any file system that is beneath the RPOOL but not beneath the root file system you are using in that moment).

Explained with an example:

    tank/RPOOL/fedora-16  (mountpoint /)
    tank/RPOOL/fedora-16/usr  (mountpoint /usr)
    tank/RPOOL/opensuse  (mountpoint /)
    tank/RPOOL/opensuse/usr  (mountpoint /usr)
    tank/home  (mountpoint /home)

In this case, when booting Fedora 16, tank/RPOOL/fedora-16, tank/RPOOL/fedora-16/usr and tank/home will be mounted on boot.  Conversely, when booting OpenSUSE, tank/RPOOL/opensuse, tank/RPOOL/opensuse/usr and tank/home will be mounted on boot.  This way, you run *zero* risk of getting file systems mixed up, and potentially losing data as a result.

This enables extremely practical uses for ZFS.  For example, you can recursively clone your operating system from tank/RPOOL/fedora-16 to tank/RPOOL/fedora-17, reboot with tank/RPOOL/fedora-17 as root file system, then perform a potentially dangerous upgrade.  As expected, nothing in tank/RPOOL/fedora-16 will be touched during the upgrade.

HOW TO USE

1. ./configure
2. make
3. make install
4. reboot

TODO:

- support event-based import of pools wite cache devices -- there appears to be no way to detect what cache devices a pool is configured with.
- do not parse /etc/fstab -- rather ask systemd for discovered mount units and use that information instead
  key for this point is to find a way (use systemctl --no-block?) to get data on existing units from inside the generator without deadlocking
- properly regen/reload autogenerated units when mountpoint and canmount properties are changed
  - systemctl stop involved mountpoints
  - change properties
  - regenerate units
  - systemctl start involved mountpoints
- properly regen/reload autogenerated units (and their dependencies) when zpools are imported / exported
  (doable with systemctl daemon-reload, worth doing it that way?)
- properly handle two file systems that have the same mountpoint property
  (probably they are on different pools)
- support SMB zfs share / unshare
- respect the noauto property (create unit, but do not create symlink for that
  file system in local-fs.target.wants, skip it from the Requires list of all other
  ZFS file system units. atm we skip creating the unit)
- parse all existing file system units to get more file system dependencies
  at the moment we only parse fstab
- register ALL available zvols as device units
  (maybe this is done automatically by udev?)
- find a way to export pools at shutdown (probably involves pivot_root)
- MAYBE: use automount units to make ZFS mount file systems on demand, rather than
  at boot up, as they are discovered
  (potential to speed boot up even more)
- MAYBE: dynamic regeneration of units every time a zfs create / zfs rename / zfs destroy is done
- MAYBE: redirect mounting of file systems when `zfs mount` or `zfs create`  happens, shunting it
  to `systemctl start`
  this item may not be necessary, if we ascertain that systemd automatically updates
  the status of units based on zfs umount
- MAYBE: redirect unmounting of a file system to `systemctl stop`
  this item nay not be necessary (see list item above this one)
- fix grub2-mkconfig (ATM it requires recompilation with libzfs and even still, a patch to /etc/grub.d/10_linux, which I supply here)
- the systemd support masks out the initscript, so if we do something important in the initscript, it might need to be moved to independent unit files that we must install.
  For example, the SMB exports should happen only after smb.service has successfully started.

But, all in all, this works.
